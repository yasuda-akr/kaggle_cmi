{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:50:53.688194Z",
     "iopub.status.busy": "2024-11-27T04:50:53.687521Z",
     "iopub.status.idle": "2024-11-27T04:51:03.038128Z",
     "shell.execute_reply": "2024-11-27T04:51:03.036891Z",
     "shell.execute_reply.started": "2024-11-27T04:50:53.688150Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install /kaggle/child-mind-institute-problematic-internet-use/models/pytorch_tabnet/pytorch_tabnet-4.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:03.040758Z",
     "iopub.status.busy": "2024-11-27T04:51:03.040390Z",
     "iopub.status.idle": "2024-11-27T04:51:10.932301Z",
     "shell.execute_reply": "2024-11-27T04:51:10.931573Z",
     "shell.execute_reply.started": "2024-11-27T04:51:03.040720Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.base import clone, BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:10.933907Z",
     "iopub.status.busy": "2024-11-27T04:51:10.933352Z",
     "iopub.status.idle": "2024-11-27T04:51:10.938101Z",
     "shell.execute_reply": "2024-11-27T04:51:10.937257Z",
     "shell.execute_reply.started": "2024-11-27T04:51:10.933877Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:10.941054Z",
     "iopub.status.busy": "2024-11-27T04:51:10.940498Z",
     "iopub.status.idle": "2024-11-27T04:51:10.972972Z",
     "shell.execute_reply": "2024-11-27T04:51:10.972341Z",
     "shell.execute_reply.started": "2024-11-27T04:51:10.941027Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# データの処理関数\n",
    "def load_data():\n",
    "    train = pd.read_csv('/kaggle/child-mind-institute-problematic-internet-use/data/train.csv')\n",
    "    test = pd.read_csv('/kaggle/child-mind-institute-problematic-internet-use/data/test.csv')\n",
    "    sample_submission = pd.read_csv('/kaggle/child-mind-institute-problematic-internet-use/data/sample_submission.csv')\n",
    "    return train, test, sample_submission\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    if np.any(np.isinf(df)):\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname):\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:10.974262Z",
     "iopub.status.busy": "2024-11-27T04:51:10.974054Z",
     "iopub.status.idle": "2024-11-27T04:51:10.987538Z",
     "shell.execute_reply": "2024-11-27T04:51:10.986714Z",
     "shell.execute_reply.started": "2024-11-27T04:51:10.974240Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# カテゴリカル特徴量のマッピング関数\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:10.988817Z",
     "iopub.status.busy": "2024-11-27T04:51:10.988519Z",
     "iopub.status.idle": "2024-11-27T04:51:10.998819Z",
     "shell.execute_reply": "2024-11-27T04:51:10.998128Z",
     "shell.execute_reply.started": "2024-11-27T04:51:10.988760Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# オートエンコーダークラスとエンコーディング関数\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim * 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim * 3, encoding_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim * 2, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim * 2, input_dim * 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim * 3, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    data_tensor = torch.FloatTensor(df_scaled)\n",
    "    input_dim = data_tensor.shape[1]\n",
    "    autoencoder = AutoEncoder(input_dim, encoding_dim)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(data_tensor), batch_size):\n",
    "            batch = data_tensor[i: i + batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = autoencoder(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "                     \n",
    "    with torch.no_grad():\n",
    "        encoded_data = autoencoder.encoder(data_tensor).numpy()\n",
    "    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n",
    "    return df_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:11Z",
     "iopub.status.busy": "2024-11-27T04:51:10.999728Z",
     "iopub.status.idle": "2024-11-27T04:51:11.014123Z",
     "shell.execute_reply": "2024-11-27T04:51:11.013342Z",
     "shell.execute_reply.started": "2024-11-27T04:51:10.999959Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 特徴量エンジニアリング関数\n",
    "def feature_engineering(df):\n",
    "    season_cols = [col for col in df.columns if 'Season' in col]\n",
    "    df = df.drop(season_cols, axis=1)\n",
    "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
    "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
    "    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n",
    "    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n",
    "    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n",
    "    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n",
    "    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n",
    "    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n",
    "    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n",
    "    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n",
    "    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n",
    "    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n",
    "    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n",
    "    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:11.015254Z",
     "iopub.status.busy": "2024-11-27T04:51:11.015019Z",
     "iopub.status.idle": "2024-11-27T04:51:11.028815Z",
     "shell.execute_reply": "2024-11-27T04:51:11.027990Z",
     "shell.execute_reply.started": "2024-11-27T04:51:11.015231Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 評価指標関数\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_rounder(predictions, thresholds):\n",
    "    return np.where(predictions < thresholds[0], 0,\n",
    "                    np.where(predictions < thresholds[1], 1,\n",
    "                             np.where(predictions < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, predictions):\n",
    "    rounded_preds = threshold_rounder(predictions, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:11.030359Z",
     "iopub.status.busy": "2024-11-27T04:51:11.030123Z",
     "iopub.status.idle": "2024-11-27T04:51:11.041176Z",
     "shell.execute_reply": "2024-11-27T04:51:11.040537Z",
     "shell.execute_reply.started": "2024-11-27T04:51:11.030336Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TabNetラッパークラス\n",
    "class TabNetWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = TabNetRegressor(**kwargs)\n",
    "        self.imputer = SimpleImputer(strategy='median')\n",
    "        self.best_model_path = 'best_tabnet_model.pt'\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_imputed = self.imputer.fit_transform(X)\n",
    "        y = y.values if hasattr(y, 'values') else y\n",
    "        \n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_imputed, y, test_size=0.2, random_state=SEED\n",
    "        )\n",
    "        \n",
    "        self.model.fit(\n",
    "            X_train=X_train, y_train=y_train.reshape(-1, 1),\n",
    "            eval_set=[(X_valid, y_valid.reshape(-1, 1))],\n",
    "            eval_name=['valid'], eval_metric=['mse'],\n",
    "            max_epochs=500, patience=50, batch_size=1024,\n",
    "            virtual_batch_size=128, num_workers=0, drop_last=False,\n",
    "            callbacks=[TabNetPretrainedModelCheckpoint(\n",
    "                filepath=self.best_model_path,\n",
    "                monitor='valid_mse', mode='min',\n",
    "                save_best_only=True, verbose=True\n",
    "            )]\n",
    "        )\n",
    "        \n",
    "        if os.path.exists(self.best_model_path):\n",
    "            self.model.load_model(self.best_model_path)\n",
    "            os.remove(self.best_model_path)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_imputed = self.imputer.transform(X)\n",
    "        return self.model.predict(X_imputed).flatten()\n",
    "\n",
    "class TabNetPretrainedModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, monitor='val_loss', mode='min', save_best_only=True, verbose=1):\n",
    "        super().__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_best_only = save_best_only\n",
    "        self.verbose = verbose\n",
    "        self.best = float('inf') if mode == 'min' else -float('inf')\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.model = self.trainer\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "        if (self.mode == 'min' and current < self.best) or (self.mode == 'max' and current > self.best):\n",
    "            if self.verbose:\n",
    "                print(f'\\nEpoch {epoch}: {self.monitor} improved from {self.best:.4f} to {current:.4f}')\n",
    "            self.best = current\n",
    "            if self.save_best_only:\n",
    "                self.model.save_model(self.filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:11.044161Z",
     "iopub.status.busy": "2024-11-27T04:51:11.043854Z",
     "iopub.status.idle": "2024-11-27T04:51:11.062387Z",
     "shell.execute_reply": "2024-11-27T04:51:11.061758Z",
     "shell.execute_reply.started": "2024-11-27T04:51:11.044135Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample_submission['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T05:16:35.719248Z",
     "iopub.status.busy": "2024-11-26T05:16:35.718760Z",
     "iopub.status.idle": "2024-11-26T05:16:35.724664Z",
     "shell.execute_reply": "2024-11-26T05:16:35.723162Z",
     "shell.execute_reply.started": "2024-11-26T05:16:35.719211Z"
    }
   },
   "source": [
    "### データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:51:11.063636Z",
     "iopub.status.busy": "2024-11-27T04:51:11.063400Z",
     "iopub.status.idle": "2024-11-27T04:52:26.328404Z",
     "shell.execute_reply": "2024-11-27T04:52:26.327703Z",
     "shell.execute_reply.started": "2024-11-27T04:51:11.063613Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:55<00:00,  8.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train, test, sample_submission = load_data()\n",
    "train_ts = load_time_series(\"/kaggle/child-mind-institute-problematic-internet-use/data/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/child-mind-institute-problematic-internet-use/data/series_test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:26.330158Z",
     "iopub.status.busy": "2024-11-27T04:52:26.329883Z",
     "iopub.status.idle": "2024-11-27T04:52:37.490251Z",
     "shell.execute_reply": "2024-11-27T04:52:37.489404Z",
     "shell.execute_reply.started": "2024-11-27T04:52:26.330131Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.9875\n",
      "Epoch [20/100], Loss: 0.9463\n",
      "Epoch [30/100], Loss: 0.9280\n",
      "Epoch [40/100], Loss: 0.8962\n",
      "Epoch [50/100], Loss: 0.8819\n",
      "Epoch [60/100], Loss: 0.8789\n",
      "Epoch [70/100], Loss: 0.8782\n",
      "Epoch [80/100], Loss: 0.8759\n",
      "Epoch [90/100], Loss: 0.8759\n",
      "Epoch [100/100], Loss: 0.8730\n",
      "Epoch [10/100], Loss: 0.9895\n",
      "Epoch [20/100], Loss: 0.5617\n",
      "Epoch [30/100], Loss: 0.4271\n",
      "Epoch [40/100], Loss: 0.4271\n",
      "Epoch [50/100], Loss: 0.4271\n",
      "Epoch [60/100], Loss: 0.4271\n",
      "Epoch [70/100], Loss: 0.4271\n",
      "Epoch [80/100], Loss: 0.4271\n",
      "Epoch [90/100], Loss: 0.4271\n",
      "Epoch [100/100], Loss: 0.4271\n"
     ]
    }
   ],
   "source": [
    "# 'id'列を削除\n",
    "df_train_ts = train_ts.drop('id', axis=1)\n",
    "df_test_ts = test_ts.drop('id', axis=1)\n",
    "\n",
    "# オートエンコーダーを適用\n",
    "train_ts_encoded = perform_autoencoder(df_train_ts, encoding_dim=60, epochs=100, batch_size=32)\n",
    "test_ts_encoded = perform_autoencoder(df_test_ts, encoding_dim=60, epochs=100, batch_size=32)\n",
    "\n",
    "# 'id'列を再度追加\n",
    "time_series_cols = train_ts_encoded.columns.tolist()\n",
    "train_ts_encoded['id'] = train_ts['id']\n",
    "test_ts_encoded['id'] = test_ts['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:37.491908Z",
     "iopub.status.busy": "2024-11-27T04:52:37.491289Z",
     "iopub.status.idle": "2024-11-27T04:52:37.516387Z",
     "shell.execute_reply": "2024-11-27T04:52:37.515694Z",
     "shell.execute_reply.started": "2024-11-27T04:52:37.491872Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 時系列データをメインデータセットとマージ\n",
    "train = pd.merge(train, train_ts_encoded, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts_encoded, how=\"left\", on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:37.517584Z",
     "iopub.status.busy": "2024-11-27T04:52:37.517314Z",
     "iopub.status.idle": "2024-11-27T04:52:44.375745Z",
     "shell.execute_reply": "2024-11-27T04:52:44.375049Z",
     "shell.execute_reply.started": "2024-11-27T04:52:37.517554Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# knnにより欠損値を補完\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputed_data = imputer.fit_transform(train[numeric_cols])\n",
    "train_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "train_imputed['sii'] = train_imputed['sii'].round().astype(int)\n",
    "for col in train.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_imputed[col] = train[col]\n",
    "\n",
    "train = train_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:44.377082Z",
     "iopub.status.busy": "2024-11-27T04:52:44.376805Z",
     "iopub.status.idle": "2024-11-27T04:52:44.408452Z",
     "shell.execute_reply": "2024-11-27T04:52:44.407591Z",
     "shell.execute_reply.started": "2024-11-27T04:52:44.377056Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 特徴量エンジニアリング\n",
    "train = feature_engineering(train)\n",
    "train = train.dropna(thresh=10, axis=0)\n",
    "test = feature_engineering(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:44.410649Z",
     "iopub.status.busy": "2024-11-27T04:52:44.410368Z",
     "iopub.status.idle": "2024-11-27T04:52:44.416460Z",
     "shell.execute_reply": "2024-11-27T04:52:44.415837Z",
     "shell.execute_reply.started": "2024-11-27T04:52:44.410613Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.drop('id', axis=1)\n",
    "test  = test .drop('id', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:44.417639Z",
     "iopub.status.busy": "2024-11-27T04:52:44.417416Z",
     "iopub.status.idle": "2024-11-27T04:52:44.428362Z",
     "shell.execute_reply": "2024-11-27T04:52:44.427671Z",
     "shell.execute_reply.started": "2024-11-27T04:52:44.417616Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train[list(test.columns)+ ['sii']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:44.429790Z",
     "iopub.status.busy": "2024-11-27T04:52:44.429452Z",
     "iopub.status.idle": "2024-11-27T04:52:44.443329Z",
     "shell.execute_reply": "2024-11-27T04:52:44.442630Z",
     "shell.execute_reply.started": "2024-11-27T04:52:44.429734Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if np.any(np.isinf(train)):\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの訓練と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:44.444694Z",
     "iopub.status.busy": "2024-11-27T04:52:44.444370Z",
     "iopub.status.idle": "2024-11-27T04:52:44.454277Z",
     "shell.execute_reply": "2024-11-27T04:52:44.453642Z",
     "shell.execute_reply.started": "2024-11-27T04:52:44.444658Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LightGBMのパラメータ\n",
    "lgb_params = {\n",
    "    'learning_rate': 0.046,\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 478,\n",
    "    'min_data_in_leaf': 13,\n",
    "    'feature_fraction': 0.893,\n",
    "    'bagging_fraction': 0.784,\n",
    "    'bagging_freq': 4,\n",
    "    'lambda_l1': 10,  # Increased from 6.59\n",
    "    'lambda_l2': 0.01,  # Increased from 2.68e-06\n",
    "    #'device': 'gpu'\n",
    "\n",
    "}\n",
    "\n",
    "# XGBoostのパラメータ\n",
    "xgb_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1,  # Increased from 0.1\n",
    "    'reg_lambda': 5,  # Increased from 1\n",
    "    'random_state': SEED,\n",
    "    'tree_method': 'gpu_hist',\n",
    "\n",
    "}\n",
    "\n",
    "# CatBoostのパラメータ\n",
    "cat_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'iterations': 200,\n",
    "    'random_seed': SEED,\n",
    "    'verbose': 0,\n",
    "    'l2_leaf_reg': 10,  # Increase this value\n",
    "    'task_type': 'GPU'\n",
    "\n",
    "}\n",
    "\n",
    "# TabNetのパラメータ\n",
    "tabnet_params = {\n",
    "    'n_d': 64,              # Width of the decision prediction layer\n",
    "    'n_a': 64,              # Width of the attention embedding for each step\n",
    "    'n_steps': 5,           # Number of steps in the architecture\n",
    "    'gamma': 1.5,           # Coefficient for feature selection regularization\n",
    "    'n_independent': 2,     # Number of independent GLU layer in each GLU block\n",
    "    'n_shared': 2,          # Number of shared GLU layer in each GLU block\n",
    "    'lambda_sparse': 1e-4,  # Sparsity regularization\n",
    "    'optimizer_fn': torch.optim.Adam,\n",
    "    'optimizer_params': dict(lr=2e-2, weight_decay=1e-5),\n",
    "    'mask_type': 'entmax',\n",
    "    'scheduler_params': dict(mode=\"min\", patience=10, min_lr=1e-5, factor=0.5),\n",
    "    'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    'verbose': 1,\n",
    "    'device_name': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:44.455561Z",
     "iopub.status.busy": "2024-11-27T04:52:44.455266Z",
     "iopub.status.idle": "2024-11-27T04:52:44.483067Z",
     "shell.execute_reply": "2024-11-27T04:52:44.482431Z",
     "shell.execute_reply.started": "2024-11-27T04:52:44.455518Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# モデルのインスタンス化\n",
    "lgb_model = LGBMRegressor(**lgb_params, random_state=SEED, verbose=-1, n_estimators=300)\n",
    "xgb_model = XGBRegressor(**xgb_params)\n",
    "cat_model = CatBoostRegressor(**cat_params)\n",
    "tabnet_model = TabNetWrapper(**tabnet_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:44.484361Z",
     "iopub.status.busy": "2024-11-27T04:52:44.484027Z",
     "iopub.status.idle": "2024-11-27T04:52:44.494187Z",
     "shell.execute_reply": "2024-11-27T04:52:44.493468Z",
     "shell.execute_reply.started": "2024-11-27T04:52:44.484324Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# モデルをVoting Regressorで結合\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', lgb_model),\n",
    "    ('xgboost', xgb_model),\n",
    "    ('catboost', cat_model),\n",
    "    ('tabnet', tabnet_model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T04:52:44.495549Z",
     "iopub.status.busy": "2024-11-27T04:52:44.495222Z",
     "iopub.status.idle": "2024-11-27T04:54:58.103101Z",
     "shell.execute_reply": "2024-11-27T04:54:58.102081Z",
     "shell.execute_reply.started": "2024-11-27T04:52:44.495513Z"
    },
    "metadata": {},
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [03:06<00:00, 37.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.7493\n",
      "Mean Validation QWK ---> 0.4699\n",
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.528\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Submission = TrainML(ensemble_model, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUメモリの解放\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
